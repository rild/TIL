##　雑記
### 講義中のメモ
regression problem (<-> classtaring)

transcription?
 speech waveform
 given text

synthesized speech

data fragmentation
main issue

8-16
16-24

1sec
50 -> 20


categoricla distribution
histogram

multimodal
not nuni

-> softmax

### 質疑応答のメモ
10時間
最低

50時間
2人

学習データ
増やしたほうがいい音がする

人間の音声生成はランダム性が高い

マルチモーダル

低レイヤーのモデルでの抽出では対応しきれない

モデルの解釈はまだできていない
多分、フーリエ変換的なことをしているのだろう

softmaxでは近傍の情報を強くすることは難しい？
十分な学習データがあれば問題なかった

F0が高くても低くても学習される

感情データを再現するように合成する (edited)


[2:05]
信号を再現しなさい

ではなく、

聞きやすい音を学習しなさい
というLossが入れられたらいいんじゃないか


[2:05]
ぼんやりと思ってる


[2:06]
スケールを変えたときどうなるか


[2:06]
レイヤーを増やさないといけない
パラメーター倍

したがって学習データも倍？


[2:07]
正規化、ベイズ推定とかいれればもっと小さくできるかも

[2:07]
2週間くらい
32個のGPU

[2:08]
LimitedDomainでは生き残るはず
Concatinate

[2:08]
駅の案内とか

[2:08]
mobileは？

これはまだ無理

[2:09]
パラメトリック


[2:09]
でも変わるかも


[2:09]
学習データにないものは動かせない


[2:10]
Vocaloidの一部の曲みたいな、人間には出せない声はだせない


[2:10]
そんな学習データが存在しないものではダメ


[2:11]
そういうものなら
パラメトリック、波形接続とかで


[2:11]
動くけど、お金がかかる

[2:11]
笑

[2:11]
ダウンサイジング

[2:11]
課題

[2:13]
removed redundant computation
complicated optimization to cloud tpu
model tuning


[2:14]
F0, duration
継続長
は事前にわかっている状態で、

波形を生成する問題

だからデータが少なくても動くと思う


[2:14]
30～40時間くらい


[2:15]
GPUが高性能化したら、普通に動くのでは


[2:15]
韻律モデルを改善すれば、もっとよくなると思う
